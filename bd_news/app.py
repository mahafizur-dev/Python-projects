from flask import Flask, render_template
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import threading

app = Flask(__name__)

# ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ó‡ßç‡¶≤‡ßã‡¶¨‡¶æ‡¶≤ ‡¶≠‡ßá‡¶∞‡¶ø‡ßü‡ßá‡¶¨‡¶≤
cached_headlines = []
last_scraped = datetime.min


def fetch_headlines():
    print("üîÑ ‡¶π‡ßá‡¶°‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™ ‡¶ö‡¶≤‡¶õ‡ßá...")
    url = 'https://www.prothomalo.com/'
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')
    headlines = soup.find_all('h3')

    extracted = []

    for h in headlines:
        a_tag = h.find('a')
        if a_tag and a_tag.text.strip():
            title = a_tag.text.strip()
            link = a_tag['href']
            if not link.startswith('http'):
                link = 'https://www.prothomalo.com' + link
            extracted.append({'title': title, 'url': link})

    return extracted


def update_cache():
    global cached_headlines, last_scraped
    now = datetime.now()
    if now - last_scraped > timedelta(hours=1):
        cached_headlines = fetch_headlines()
        last_scraped = now
    else:
        print("‚úÖ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂‡¶° ‡¶π‡ßá‡¶°‡¶≤‡¶æ‡¶á‡¶® ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§")


@app.route('/')
def home():
    update_cache()
    return render_template('index.html', headlines=cached_headlines)


# Flask ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶π‡¶ì‡ßü‡¶æ‡¶∞ ‡¶™‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ò‡¶£‡ßç‡¶ü‡¶æ‡ßü ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶ó‡ßç‡¶∞‡¶æ‡¶â‡¶®‡ßç‡¶°‡ßá ‡¶Ö‡¶ü‡ßã-‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï)
def auto_scraper_loop():
    while True:
        update_cache()
        threading.Event().wait(3600)  # ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ßß ‡¶ò‡¶®‡ßç‡¶ü‡¶æ (3600 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°)


if __name__ == '__main__':
    threading.Thread(target=auto_scraper_loop, daemon=True).start()
    app.run(debug=True)
